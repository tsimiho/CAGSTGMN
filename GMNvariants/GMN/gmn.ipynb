{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import compute_similarity, auc\n",
    "from loss import pairwise_loss, triplet_loss\n",
    "from gmn_utils import *\n",
    "from configure import *\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GATConv, dense_mincut_pool\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch\n",
    "from torch_geometric.nn import dense_mincut_pool\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATWithMinCutPooling(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features,\n",
    "        num_classes,\n",
    "        num_hidden=8,\n",
    "        heads=8,\n",
    "        dropout=0.6,\n",
    "        name=\"GAT\",\n",
    "    ):  \n",
    "        super(GATWithMinCutPooling, self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "        self.conv1 = GATConv(\n",
    "            in_channels=num_features,\n",
    "            out_channels=num_hidden,\n",
    "            heads=heads,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.conv2 = GATConv(\n",
    "            in_channels=num_hidden * heads,\n",
    "            out_channels=num_classes,\n",
    "            heads=1,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.feature_transform = torch.nn.Linear(num_classes, num_features)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = F.dropout(data.x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, data.edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "        \n",
    "        x_dense, mask = to_dense_batch(data.x, data.batch)\n",
    "        adj_dense = to_dense_adj(data.edge_index, data.batch)\n",
    "\n",
    "        num_clusters = dataset.num_classes\n",
    "\n",
    "        transform = torch.nn.Linear(x.size(1), num_clusters)\n",
    "        s = transform(x)\n",
    "        s = torch.softmax(s, dim=1)\n",
    "\n",
    "        x_pool, adj_pool, mincut_loss, ortho_loss = dense_mincut_pool(x_dense, adj_dense, s, mask=mask)\n",
    "        x_pool = x_pool.squeeze(0)\n",
    "\n",
    "        return x, x_pool, adj_pool, mincut_loss, ortho_loss\n",
    "\n",
    "classification_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "    classification_loss = classification_criterion(x_class[data.train_mask], data.y[data.train_mask])\n",
    "    loss = classification_loss + mincut_loss + ortho_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "def validate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "        classification_loss = classification_criterion(x_class[data.val_mask], data.y[data.val_mask])\n",
    "        loss = classification_loss + mincut_loss + ortho_loss\n",
    "        return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "        classification_loss = classification_criterion(x_class[data.test_mask], data.y[data.test_mask])\n",
    "        loss = classification_loss + mincut_loss + ortho_loss\n",
    "        return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "dataset = Planetoid(root='../Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "classification_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "    classification_loss = classification_criterion(x_class[data.train_mask], data.y[data.train_mask])\n",
    "    loss = classification_loss + mincut_loss + ortho_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "def validate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "        classification_loss = classification_criterion(x_class[data.val_mask], data.y[data.val_mask])\n",
    "        loss = classification_loss + mincut_loss + ortho_loss\n",
    "        return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_class, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "        classification_loss = classification_criterion(x_class[data.test_mask], data.y[data.test_mask])\n",
    "        loss = classification_loss + mincut_loss + ortho_loss\n",
    "        return loss.item(), classification_loss, mincut_loss, ortho_loss\n",
    "\n",
    "dataset = Planetoid(root='../Cora', name='Cora')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8867822289466858\n",
      "\ttest_class_loss = 0.7749300599098206, test_mincut_loss = -0.9989656209945679, test_ortho_loss = 1.110817790031433\n"
     ]
    }
   ],
   "source": [
    "final_model = GATWithMinCutPooling(num_features=dataset.num_features, num_classes=dataset.num_classes, dropout=0.6)\n",
    "optimizer = torch.optim.Adam(final_model.parameters(), lr=0.005)    \n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_class_loss, train_mincut_loss, train_ortho_loss = train(final_model, data, optimizer)\n",
    "             \n",
    "test_loss, test_class_loss, test_mincut_loss, test_ortho_loss = test(final_model, data)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f'\\ttest_class_loss = {test_class_loss}, test_mincut_loss = {test_mincut_loss}, test_ortho_loss = {test_ortho_loss}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = final_model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out, x_pool, adj_pool, mincut_loss, ortho_loss = model(data)\n",
    "\n",
    "edge_index_pool = dense_to_sparse(adj_pool)[0]\n",
    "\n",
    "pooled_data = Data(x=x_pool, edge_index=edge_index_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Data(x=data.x, edge_index=data.edge_index)\n",
    "g2 = pooled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder= {'node_hidden_sizes': [64], 'node_feature_dim': 1, 'edge_hidden_sizes': [4]}\n",
      "aggregator= {'node_hidden_sizes': [128], 'graph_transform_sizes': [128], 'input_size': [64], 'gated': True, 'aggregation_type': 'sum'}\n",
      "graph_embedding_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching'}\n",
      "graph_matching_net= {'node_state_dim': 64, 'edge_state_dim': 4, 'edge_hidden_sizes': [128, 128], 'node_hidden_sizes': [128], 'n_prop_layers': 5, 'share_prop_params': True, 'edge_net_init_scale': 0.1, 'node_update_type': 'gru', 'use_reverse_direction': True, 'reverse_dir_param_different': False, 'layer_norm': False, 'prop_type': 'matching', 'similarity': 'dotproduct'}\n",
      "model_type= matching\n",
      "data= {'problem': 'graph_edit_distance', 'dataset_params': {'n_nodes_range': [20, 20], 'p_edge_range': [0.2, 0.2], 'n_changes_positive': 1, 'n_changes_negative': 2, 'validation_dataset_size': 1000}}\n",
      "training= {'batch_size': 20, 'learning_rate': 0.0001, 'mode': 'pair', 'loss': 'margin', 'margin': 1.0, 'graph_vec_regularizer_weight': 1e-06, 'clip_value': 10.0, 'n_training_steps': 100000, 'print_after': 100, 'eval_after': 10}\n",
      "evaluation= {'batch_size': 20}\n",
      "seed= 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphMatchingNet(\n",
       "  (_encoder): GraphEncoder(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=64, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_aggregator): GraphAggregator(\n",
       "    (MLP1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    )\n",
       "    (MLP2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (_prop_layers): ModuleList(\n",
       "    (0-4): 5 x GraphPropMatchingLayer(\n",
       "      (_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (_reverse_message_net): Sequential(\n",
       "        (0): Linear(in_features=132, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (GRU): GRU(192, 64)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Print configure\n",
    "config = get_default_config()\n",
    "for k, v in config.items():\n",
    "    print(\"%s= %s\" % (k, v))\n",
    "\n",
    "# Set random seeds\n",
    "seed = config[\"seed\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed + 1)\n",
    "torch.manual_seed(seed + 2)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "training_set, validation_set = build_datasets(config)\n",
    "\n",
    "if config[\"training\"][\"mode\"] == \"pair\":\n",
    "    training_data_iter = training_set.pairs(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs, _ = next(training_data_iter)\n",
    "else:\n",
    "    training_data_iter = training_set.triplets(config[\"training\"][\"batch_size\"])\n",
    "    first_batch_graphs = next(training_data_iter)\n",
    "\n",
    "node_feature_dim = first_batch_graphs.node_features.shape[-1]\n",
    "edge_feature_dim = first_batch_graphs.edge_features.shape[-1]\n",
    "\n",
    "model, optimizer = build_model(config, node_feature_dim, edge_feature_dim)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/st/cyh3v8ln22sdswp1s386w5vw0000gn/T/ipykernel_9648/1308496964.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from_idx = torch.tensor(from_idx, dtype=torch.long)\n",
      "/var/folders/st/cyh3v8ln22sdswp1s386w5vw0000gn/T/ipykernel_9648/1308496964.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  to_idx = torch.tensor(to_idx, dtype=torch.long)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5416x32 and 8x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m stacked_to_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((to_idx, to_idx\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m+\u001b[39mg1\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     29\u001b[0m stacked_graph_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mzeros(g1\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)), torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mones(g1\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m))))\n\u001b[0;32m---> 31\u001b[0m graph_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked_node_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked_edge_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked_from_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked_to_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstacked_graph_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m x, y \u001b[38;5;241m=\u001b[39m reshape_and_split_tensor(graph_vectors, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     41\u001b[0m similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(x, y)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/NTUA/ECE/DiplomaThesis/Code/repo/GMNvariants/GMN/graphembeddingnetwork.py:597\u001b[0m, in \u001b[0;36mGraphEmbeddingNet.forward\u001b[0;34m(self, node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28mself\u001b[39m, node_features, edge_features, from_idx, to_idx, graph_idx, n_graphs\n\u001b[1;32m    581\u001b[0m ):\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute graph representations.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m        graph representations.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     node_features, edge_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     node_states \u001b[38;5;241m=\u001b[39m node_features\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m [node_states]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/NTUA/ECE/DiplomaThesis/Code/repo/GMNvariants/GMN/graphembeddingnetwork.py:78\u001b[0m, in \u001b[0;36mGraphEncoder.forward\u001b[0;34m(self, node_features, edge_features)\u001b[0m\n\u001b[1;32m     76\u001b[0m     node_outputs \u001b[38;5;241m=\u001b[39m node_features\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     node_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMLP1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_hidden_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m     edge_outputs \u001b[38;5;241m=\u001b[39m edge_features\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5416x32 and 8x64)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "\n",
    "pca = PCA(n_components=32)\n",
    "reduced_node_features = pca.fit_transform(g1.x)\n",
    "\n",
    "from_idx = g1.edge_index[0]\n",
    "to_idx = g1.edge_index[1]\n",
    "\n",
    "num_edges = g1.edge_index.shape[1]\n",
    "\n",
    "graph_idx = np.zeros(g1.x.shape[0], dtype=int)\n",
    "\n",
    "node_features = torch.tensor(reduced_node_features, dtype=torch.float32)\n",
    "edge_features = torch.ones((num_edges, 4), dtype=torch.float32)\n",
    "from_idx = torch.tensor(from_idx, dtype=torch.long)\n",
    "to_idx = torch.tensor(to_idx, dtype=torch.long)\n",
    "graph_idx = torch.tensor(graph_idx, dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "stacked_node_features = torch.cat((node_features, node_features.clone()))\n",
    "stacked_edge_features = torch.cat((edge_features, edge_features.clone()))\n",
    "\n",
    "stacked_from_idx = torch.cat((from_idx, from_idx.clone()+g1.x.shape[0]))\n",
    "stacked_to_idx = torch.cat((to_idx, to_idx.clone()+g1.x.shape[0]))\n",
    "\n",
    "stacked_graph_idx = torch.cat((torch.tensor(np.zeros(g1.x.shape[0], dtype=int)), torch.tensor(np.ones(g1.x.shape[0], dtype=int))))\n",
    "\n",
    "graph_vectors = model(\n",
    "        stacked_node_features.to(device),\n",
    "        stacked_edge_features.to(device),\n",
    "        stacked_from_idx.to(device), \n",
    "        stacked_to_idx.to(device),\n",
    "        stacked_graph_idx.to(device),\n",
    "        2\n",
    "    )\n",
    "\n",
    "x, y = reshape_and_split_tensor(graph_vectors, 2)\n",
    "similarity = cosine_similarity(x, y)\n",
    "print(similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
